{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiBV+HIjYwtGDvLSV3IC5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codal-tshah/data-practices-2024/blob/22_apr/PySpark/PySpark_DataFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH_I-Xy4ZSm0",
        "outputId": "cd194872-5cf5-4c76-dfc7-94f33093e98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=e27aabf0d87b734195c99b532b0e9d2b9c520ed8af067bd56c2d1c6f6eb3ff3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaJyttNvYADj"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkExample.com').getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create an empty DataFrame**"
      ],
      "metadata": {
        "id": "JuxtBHPuaaJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emptyRDD = spark.sparkContext.emptyRDD()\n",
        "print(emptyRDD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvhT5Ov4ZRJ2",
        "outputId": "1f6ef908-41ed-42c5-9a99-fc15407dc663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Empty DataFrame with Schema (StructType)**"
      ],
      "metadata": {
        "id": "843IRTKPfyXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "schema = StructType([\n",
        "  StructField('firstname', StringType(), True),\n",
        "  StructField('middlename', StringType(), True),\n",
        "  StructField('lastname', StringType(), True)\n",
        "  ])"
      ],
      "metadata": {
        "id": "fNOpqmmfaPzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(emptyRDD,schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7laxWdqf3Uq",
        "outputId": "18d4ad20-6741-4f0f-9f5c-785373d875e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n",
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Empty RDD to DataFrame**"
      ],
      "metadata": {
        "id": "pzNFpIlCf9ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.createDataFrame([],schema)\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AgL8VVQf6cN",
        "outputId": "1a08d7a3-e19e-4392-b298-a7b9832ee0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n",
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert PySpark RDD to DataFrame**"
      ],
      "metadata": {
        "id": "eDEAYfpOgheA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create PySpark RDD**"
      ],
      "metadata": {
        "id": "bJg4riYxhJwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
        "rdd = spark.sparkContext.parallelize(dept)"
      ],
      "metadata": {
        "id": "4X2E9Kp8hJNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = rdd.toDF()\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJiUoBdggIOE",
        "outputId": "dfdfa41c-6f84-4074-c81a-a08381970d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            "\n",
            "+---------+---+\n",
            "|_1       |_2 |\n",
            "+---------+---+\n",
            "|Finance  |10 |\n",
            "|Marketing|20 |\n",
            "|Sales    |30 |\n",
            "|IT       |40 |\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "df2 = rdd.toDF(deptColumns)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlQBlD2xhsMc",
        "outputId": "91b21543-9b77-408e-8be7-88e6f1eb9151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deptDF = spark.createDataFrame(rdd, schema = deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inqd-I6oh9L5",
        "outputId": "bd171e8f-1ad9-4f8e-8fc0-7cf362ef7bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Completed Example**"
      ],
      "metadata": {
        "id": "Lh1CWW0SiVlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
        "rdd = spark.sparkContext.parallelize(dept)\n",
        "\n",
        "df = rdd.toDF()\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "df2 = rdd.toDF(deptColumns)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)\n",
        "\n",
        "deptDF = spark.createDataFrame(rdd, schema = deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)\n",
        "\n",
        "from pyspark.sql.types import StructType,StructField, StringType\n",
        "deptSchema = StructType([\n",
        "    StructField('dept_name', StringType(), True),\n",
        "    StructField('dept_id', StringType(), True)\n",
        "])\n",
        "\n",
        "deptDF1 = spark.createDataFrame(rdd, schema = deptSchema)\n",
        "deptDF1.printSchema()\n",
        "deptDF1.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teB2N1-riOl8",
        "outputId": "054cf078-9ea2-4f95-bbda-6568a7fd302b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _1: string (nullable = true)\n",
            " |-- _2: long (nullable = true)\n",
            "\n",
            "+---------+---+\n",
            "|_1       |_2 |\n",
            "+---------+---+\n",
            "|Finance  |10 |\n",
            "|Marketing|20 |\n",
            "|Sales    |30 |\n",
            "|IT       |40 |\n",
            "+---------+---+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: string (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SHOW()"
      ],
      "metadata": {
        "id": "ACshNuDFsRGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZt9Qh6nqjM1",
        "outputId": "bc02c946-d984-4760-b729-98f45ab6933c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|  Finance|     10|\n",
            "|Marketing|     20|\n",
            "|    Sales|     30|\n",
            "|       IT|     40|\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(2,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmlk2Cj6iYgo",
        "outputId": "d625a816-3d24-4aac-d5ed-3b9b5836ae5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "+---------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(2,truncate=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03-oF8-Sqkrz",
        "outputId": "01627a49-74f5-4726-9b60-bb02e7c512fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|      Fin|     10|\n",
            "|      Mar|     20|\n",
            "+---------+-------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(2,truncate=False, vertical=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbPEpul8q3bT",
        "outputId": "fa24685a-e3ad-43bc-e276-4aaa279060a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0--------------\n",
            " dept_name | Finance   \n",
            " dept_id   | 10        \n",
            "-RECORD 1--------------\n",
            " dept_name | Marketing \n",
            " dept_id   | 20        \n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.schema.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7h8IF-Fq97i",
        "outputId": "5f0e8df0-21c0-422f-b36e-fad87b27b4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"fields\":[{\"metadata\":{},\"name\":\"dept_name\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"dept_id\",\"nullable\":true,\"type\":\"long\"}],\"type\":\"struct\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6p0_f6ttxA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **StructType & StructField**"
      ],
      "metadata": {
        "id": "nGTRu73iuTMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,ArrayType,MapType\n",
        "from pyspark.sql.functions import col,struct,when\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[1]\") \\\n",
        "                    .appName('SparkByExamples.com') \\\n",
        "                    .getOrCreate()\n",
        "\n",
        "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
        "  ]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"firstname\",StringType(),True),\n",
        "    StructField(\"middlename\",StringType(),True),\n",
        "    StructField(\"lastname\",StringType(),True),\n",
        "    StructField(\"id\", StringType(), True),\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"salary\", IntegerType(), True)\n",
        "  ])\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "structureData = [\n",
        "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
        "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
        "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
        "  ]\n",
        "structureSchema = StructType([\n",
        "        StructField('name', StructType([\n",
        "             StructField('firstname', StringType(), True),\n",
        "             StructField('middlename', StringType(), True),\n",
        "             StructField('lastname', StringType(), True)\n",
        "             ])),\n",
        "         StructField('id', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('salary', IntegerType(), True)\n",
        "         ])\n",
        "\n",
        "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)\n",
        "\n",
        "\n",
        "updatedDF = df2.withColumn(\"OtherInfo\",\n",
        "    struct(col(\"id\").alias(\"identifier\"),\n",
        "    col(\"gender\").alias(\"gender\"),\n",
        "    col(\"salary\").alias(\"salary\"),\n",
        "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
        "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
        "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
        "  )).drop(\"id\",\"gender\",\"salary\")\n",
        "\n",
        "updatedDF.printSchema()\n",
        "updatedDF.show(truncate=False)\n",
        "\n",
        "\n",
        "\"\"\" Array & Map\"\"\"\n",
        "\n",
        "\n",
        "arrayStructureSchema = StructType([\n",
        "    StructField('name', StructType([\n",
        "       StructField('firstname', StringType(), True),\n",
        "       StructField('middlename', StringType(), True),\n",
        "       StructField('lastname', StringType(), True)\n",
        "       ])),\n",
        "       StructField('hobbies', ArrayType(StringType()), True),\n",
        "       StructField('properties', MapType(StringType(),StringType()), True)\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Qkm_RhuUal",
        "outputId": "54406c25-20d8-4e4f-9882-39925ba61af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|id   |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+--------------------+-----+------+------+\n",
            "|name                |id   |gender|salary|\n",
            "+--------------------+-----+------+------+\n",
            "|{James, , Smith}    |36636|M     |3100  |\n",
            "|{Michael, Rose, }   |40288|M     |4300  |\n",
            "|{Robert, , Williams}|42114|M     |1400  |\n",
            "|{Maria, Anne, Jones}|39192|F     |5500  |\n",
            "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
            "+--------------------+-----+------+------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- OtherInfo: struct (nullable = false)\n",
            " |    |-- identifier: string (nullable = true)\n",
            " |    |-- gender: string (nullable = true)\n",
            " |    |-- salary: integer (nullable = true)\n",
            " |    |-- Salary_Grade: string (nullable = false)\n",
            "\n",
            "+--------------------+------------------------+\n",
            "|name                |OtherInfo               |\n",
            "+--------------------+------------------------+\n",
            "|{James, , Smith}    |{36636, M, 3100, Medium}|\n",
            "|{Michael, Rose, }   |{40288, M, 4300, High}  |\n",
            "|{Robert, , Williams}|{42114, M, 1400, Low}   |\n",
            "|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n",
            "|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n",
            "+--------------------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Column Class | Operators & Functions**"
      ],
      "metadata": {
        "id": "Vzeg0KxYDsc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Column Class Object**"
      ],
      "metadata": {
        "id": "qDDCEqc7F75k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "colObj = lit(\"sparkbyexamples.com\")"
      ],
      "metadata": {
        "id": "AYSvSb8SuUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"James\",23),(\"Ann\",40)]\n",
        "df=spark.createDataFrame(data).toDF(\"name\",\"gender\")\n",
        "df.printSchema()\n",
        "\n",
        "# Using DataFrame object (df)\n",
        "df.select(df.gender).show()\n",
        "df.select(df[\"gender\"]).show()\n",
        "#Accessing column name with dot (with backticks)\n",
        "df.select(df[\"`name`\"]).show()\n",
        "\n",
        "#Using SQL col() function\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col(\"gender\")).show()\n",
        "#Accessing column name with dot (with backticks)\n",
        "df.select(col(\"`name`\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOiGveIZv6-H",
        "outputId": "1fff5751-8535-4f7c-d6a3-5dfa4c16a2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- gender: long (nullable = true)\n",
            "\n",
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|    23|\n",
            "|    40|\n",
            "+------+\n",
            "\n",
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|    23|\n",
            "|    40|\n",
            "+------+\n",
            "\n",
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "|James|\n",
            "|  Ann|\n",
            "+-----+\n",
            "\n",
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|    23|\n",
            "|    40|\n",
            "+------+\n",
            "\n",
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "|James|\n",
            "|  Ann|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(\"James\",\"Bond\",\"100\",None),\n",
        "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
        "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
        "      (\"Tom Brand\",None,\"400\",'M')]\n",
        "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0gJDTFaIXX6",
        "outputId": "64618ab8-8324-4901-ae77-e4121d22fc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+------+\n",
            "|     fname|lname| id|gender|\n",
            "+----------+-----+---+------+\n",
            "|     James| Bond|100|  NULL|\n",
            "|       Ann|Varsa|200|     F|\n",
            "|Tom Cruise|  XXX|400|      |\n",
            "| Tom Brand| NULL|400|     M|\n",
            "+----------+-----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#alias\n",
        "from pyspark.sql.functions import expr\n",
        "df.select(df.fname.alias(\"first_name\"),\n",
        "          df.lname.alias(\"last_name\")\n",
        "   ).show()\n",
        "\n",
        "#Another example\n",
        "df.select(expr(\" fname ||','|| lname\").alias(\"fullName\") \\\n",
        "   ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIlRqfY9GJxy",
        "outputId": "f8d533d1-fec6-4424-91f0-3f950bff2e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "|first_name|last_name|\n",
            "+----------+---------+\n",
            "|     James|     Bond|\n",
            "|       Ann|    Varsa|\n",
            "|Tom Cruise|      XXX|\n",
            "| Tom Brand|     NULL|\n",
            "+----------+---------+\n",
            "\n",
            "+--------------+\n",
            "|      fullName|\n",
            "+--------------+\n",
            "|    James,Bond|\n",
            "|     Ann,Varsa|\n",
            "|Tom Cruise,XXX|\n",
            "|          NULL|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort(df.fname.asc()).show()\n",
        "df.sort(df.fname.desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_lLv46H-Nv",
        "outputId": "968fe884-6b8c-4148-b1c9-7f79e1b331dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+------+\n",
            "|     fname|lname| id|gender|\n",
            "+----------+-----+---+------+\n",
            "|       Ann|Varsa|200|     F|\n",
            "|     James| Bond|100|  NULL|\n",
            "| Tom Brand| NULL|400|     M|\n",
            "|Tom Cruise|  XXX|400|      |\n",
            "+----------+-----+---+------+\n",
            "\n",
            "+----------+-----+---+------+\n",
            "|     fname|lname| id|gender|\n",
            "+----------+-----+---+------+\n",
            "|Tom Cruise|  XXX|400|      |\n",
            "| Tom Brand| NULL|400|     M|\n",
            "|     James| Bond|100|  NULL|\n",
            "|       Ann|Varsa|200|     F|\n",
            "+----------+-----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.id.between(100,300)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFQ4wliAIvZS",
        "outputId": "ecaba42d-bfd2-44dd-f5ba-81175e7da898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---+------+\n",
            "|fname|lname| id|gender|\n",
            "+-----+-----+---+------+\n",
            "|James| Bond|100|  NULL|\n",
            "|  Ann|Varsa|200|     F|\n",
            "+-----+-----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.fname.contains(\"B\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJjLUZe4JEb3",
        "outputId": "73795711-790d-4e44-e2da-823cb24cd86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+------+\n",
            "|    fname|lname| id|gender|\n",
            "+---------+-----+---+------+\n",
            "|Tom Brand| NULL|400|     M|\n",
            "+---------+-----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.fname,df.lname,df.id) \\\n",
        "  .filter(df.fname.like(\"%om\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMHOva_1JV07",
        "outputId": "daa1ea04-a1a8-482f-dc31-34c49d4028c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[fname: string, lname: string, id: string]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n",
        "              .when(df.gender==\"F\",\"Female\") \\\n",
        "              .when(df.gender==None ,\"\") \\\n",
        "              .otherwise(df.gender).alias(\"new_gender\") \\\n",
        "    ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KajYhmW_JxHp",
        "outputId": "ceb3f545-0db4-4e9d-e380-fe546dbf77c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----------+\n",
            "|     fname|lname|new_gender|\n",
            "+----------+-----+----------+\n",
            "|     James| Bond|      NULL|\n",
            "|       Ann|Varsa|    Female|\n",
            "|Tom Cruise|  XXX|          |\n",
            "| Tom Brand| NULL|      Male|\n",
            "+----------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.gender.isNull()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNvz2seFJ9bc",
        "outputId": "576b1291-1ace-4ee3-ff42-5090dcb3a07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---+------+\n",
            "|fname|lname| id|gender|\n",
            "+-----+-----+---+------+\n",
            "|James| Bond|100|  NULL|\n",
            "+-----+-----+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "z5abJVCDKl_h",
        "outputId": "8a4f9749-c8b0-4c90-bca8-9a49ebf6fb44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- fname: string (nullable = true)\n",
            " |-- lname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getItem() used with ArrayType\n",
        "# df.select(df.languages.getItem(1)).show()\n",
        "\n",
        "#getItem() used with MapType\n",
        "df.select(df.lname.getItem(\"xxx\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "o6OxK9wFKPca",
        "outputId": "ec541139-6f39-4fc5-b151-7b1aa62e0a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"lname\". Need a complex type [STRUCT, ARRAY, MAP] but got \"STRING\".",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a79a51190a54>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#getItem() used with MapType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetItem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xxx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \"\"\"\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [INVALID_EXTRACT_BASE_FIELD_TYPE] Can't extract a value from \"lname\". Need a complex type [STRUCT, ARRAY, MAP] but got \"STRING\"."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-03haz4YKbJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Select Columns**"
      ],
      "metadata": {
        "id": "IP-8ghPhJnzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Spark.examples.com\").getOrCreate()\n",
        "data = [(\"mahesh ihfweoifow\", \"sci\", 15, \"ssoa\"),\n",
        "    (\"ramesh\", \"comm\", 17, \"xaviers\"),\n",
        "    (\"fenil a;h;hwo;eihfwoeih\", \"arts\", 16, \"dhl\"),\n",
        "    (\"kenil\", \"sci\", 18, \"infocity\")\n",
        "]\n",
        "columns = [\"Name\", \"stream\", \"Age\", \"School\"]\n",
        "df = spark.createDataFrame(data = data, schema=columns)\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSpd9BMlJsf1",
        "outputId": "3e05a57e-3018-4800-9ac7-89f93e154ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+---+--------+\n",
            "|                Name|stream|Age|  School|\n",
            "+--------------------+------+---+--------+\n",
            "|   mahesh ihfweoifow|   sci| 15|    ssoa|\n",
            "|              ramesh|  comm| 17| xaviers|\n",
            "|fenil a;h;hwo;eih...|  arts| 16|     dhl|\n",
            "|               kenil|   sci| 18|infocity|\n",
            "+--------------------+------+---+--------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- stream: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            " |-- School: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "880fgJLSK7Yw",
        "outputId": "88bed695-0833-4e1b-c543-4f67eaeb37bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|James    |Smith   |USA    |CA   |\n",
            "|Michael  |Rose    |USA    |NY   |\n",
            "|Robert   |Williams|USA    |CA   |\n",
            "|Maria    |Jones   |USA    |FL   |\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstname\",\"lastname\").show()\n",
        "df.select(df.firstname,df.lastname).show()\n",
        "df.select(df[\"firstname\"],df[\"lastname\"]).show()\n",
        "\n",
        "#By using col() function\n",
        "from pyspark.sql.functions import col\n",
        "df.select(col(\"firstname\"),col(\"lastname\")).show()\n",
        "\n",
        "#Select columns by regular expression\n",
        "df.select(df.colRegex(\"`^.*name*`\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qX8JeVELyMe",
        "outputId": "c264ab47-7731-4e3e-b234-08d7eee8e85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|  Michael|    Rose|\n",
            "|   Robert|Williams|\n",
            "|    Maria|   Jones|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|  Michael|    Rose|\n",
            "|   Robert|Williams|\n",
            "|    Maria|   Jones|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|  Michael|    Rose|\n",
            "|   Robert|Williams|\n",
            "|    Maria|   Jones|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|  Michael|    Rose|\n",
            "|   Robert|Williams|\n",
            "|    Maria|   Jones|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|    James|   Smith|\n",
            "|  Michael|    Rose|\n",
            "|   Robert|Williams|\n",
            "|    Maria|   Jones|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(*columns).show()\n",
        "\n",
        "# Select All columns\n",
        "df.select([col for col in df.columns]).show()\n",
        "df.select(\"*\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLwS5NlsL3ff",
        "outputId": "f153acb5-2911-40ad-b01b-06de8949c2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n",
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n",
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selects first 3 columns and top 3 rows\n",
        "df.select(df.columns[:3]).show(3)\n",
        "\n",
        "#Selects columns 2 to 4  and top 3 r\n",
        "df.select(df.columns[2:4]).show(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ0qfBgsMBXp",
        "outputId": "9ea1d88e-7c3f-4193-8ade-36c8eeb3f357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------+\n",
            "|firstname|lastname|country|\n",
            "+---------+--------+-------+\n",
            "|    James|   Smith|    USA|\n",
            "|  Michael|    Rose|    USA|\n",
            "|   Robert|Williams|    USA|\n",
            "+---------+--------+-------+\n",
            "only showing top 3 rows\n",
            "\n",
            "+-------+-----+\n",
            "|country|state|\n",
            "+-------+-----+\n",
            "|    USA|   CA|\n",
            "|    USA|   NY|\n",
            "|    USA|   CA|\n",
            "+-------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUwSi2-sc_mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COLLECT()**"
      ],
      "metadata": {
        "id": "yXMypwI_dF4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**collect() is an action hence it does not return a DataFrame instead, it returns data in an Array to the driver.**"
      ],
      "metadata": {
        "id": "S9ELKAwTdg0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "dept = [(\"Finance\",10), \\\n",
        "    (\"Marketing\",20), \\\n",
        "    (\"Sales\",30), \\\n",
        "    (\"IT\",40) \\\n",
        "  ]\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "deptDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxmTZnS1dLH1",
        "outputId": "3018b556-243e-4cc4-c52d-85120bddc96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataCollect = deptDF.collect()\n",
        "print(dataCollect)"
      ],
      "metadata": {
        "id": "poSuA0xMMESg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd0340a-4f1f-4473-b3b9-c41f2ec9d860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(dept_name='Finance', dept_id=10), Row(dept_name='Marketing', dept_id=20), Row(dept_name='Sales', dept_id=30), Row(dept_name='IT', dept_id=40)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in dataCollect:\n",
        "    print(row['dept_name'] + \",\" +str(row['dept_id']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMygVA38dWgF",
        "outputId": "a11fdc7a-ace7-4a87-d22e-fffc0301cc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finance,10\n",
            "Marketing,20\n",
            "Sales,30\n",
            "IT,40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Where Filter**"
      ],
      "metadata": {
        "id": "JvBVDzimmbqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField\n",
        "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
        "data = [\n",
        "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
        "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
        "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
        " ]\n",
        "\n",
        "schema = StructType([\n",
        "     StructField('name', StructType([\n",
        "        StructField('firstname', StringType(), True),\n",
        "        StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "     ])),\n",
        "     StructField('languages', ArrayType(StringType()), True),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        " ])\n",
        "\n",
        "df = spark.createDataFrame(data = data, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl-OtFQ5lMLN",
        "outputId": "87bcd960-7d10-4c05-fed4-d5b410815b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- languages: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Anna, Rose, }        |[Spark, Java, C++]|NY   |F     |\n",
            "|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(df.state == \"OH\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0Fp_MemiDE",
        "outputId": "70eaafbb-6261-4c7f-b7b3-de4049d8af81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# not equals condition\n",
        "df.filter(df.state != \"OH\") \\\n",
        "    .show(truncate=False)\n",
        "df.filter(~(df.state == \"OH\")) \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQQL1H6_mwNS",
        "outputId": "0c19587c-c345-4e2d-d20a-14aaccfb9368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+-----+------+\n",
            "|name                |languages         |state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|{Anna, Rose, }      |[Spark, Java, C++]|NY   |F     |\n",
            "|{Maria, Anne, Jones}|[CSharp, VB]      |NY   |M     |\n",
            "|{Jen, Mary, Brown}  |[CSharp, VB]      |NY   |M     |\n",
            "+--------------------+------------------+-----+------+\n",
            "\n",
            "+--------------------+------------------+-----+------+\n",
            "|name                |languages         |state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|{Anna, Rose, }      |[Spark, Java, C++]|NY   |F     |\n",
            "|{Maria, Anne, Jones}|[CSharp, VB]      |NY   |M     |\n",
            "|{Jen, Mary, Brown}  |[CSharp, VB]      |NY   |M     |\n",
            "+--------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(\"gender <> 'M'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaorUx1-myWa",
        "outputId": "83f64d87-0780-4ca8-ab84-166f75fcca2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+-----+------+\n",
            "|               name|         languages|state|gender|\n",
            "+-------------------+------------------+-----+------+\n",
            "|     {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
            "|{Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
            "+-------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "li=[\"OH\",\"CA\",\"DE\"]\n",
        "df.filter(df.state.isin(li)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls0Z07Hsm6Zh",
        "outputId": "363126ab-75a3-4328-f649-e31be5211368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+-----+------+\n",
            "|                name|         languages|state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
            "| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n",
            "|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
            "+--------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter NOT IS IN List values\n",
        "#These show all records with NY (NY is not part of the list)\n",
        "df.filter(~df.state.isin(li)).show()\n",
        "df.filter(df.state.isin(li)==False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuDvrSwZnC9E",
        "outputId": "73682063-4843-487b-8896-432500dd957c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+-----+------+\n",
            "|                name|         languages|state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
            "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
            "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
            "+--------------------+------------------+-----+------+\n",
            "\n",
            "+--------------------+------------------+-----+------+\n",
            "|                name|         languages|state|gender|\n",
            "+--------------------+------------------+-----+------+\n",
            "|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
            "|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n",
            "|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n",
            "+--------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare Data\n",
        "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),\n",
        "     (4,\"Rames Rose\"),(5,\"Rames rose\")\n",
        "  ]\n",
        "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
        "\n",
        "# like - SQL LIKE pattern\n",
        "df2.filter(df2.name.like(\"%rose%\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmJYGEoenNEH",
        "outputId": "57f9c91c-c388-4339-a14d-49e7c8e4c7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| id|      name|\n",
            "+---+----------+\n",
            "|  5|Rames rose|\n",
            "+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPpoZU2wnsJS",
        "outputId": "10656a5c-3160-4868-afa5-05cf2edc4bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+\n",
            "| id|        name|\n",
            "+---+------------+\n",
            "|  2|Michael Rose|\n",
            "|  4|  Rames Rose|\n",
            "|  5|  Rames rose|\n",
            "+---+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Distinct to Drop Duplicate**"
      ],
      "metadata": {
        "id": "lei7eemaxlEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "distinct() transformation is used to drop/remove the duplicate rows (all columns) from DataFrame and dropDuplicates() is used to drop rows based on selected (one or multiple) columns."
      ],
      "metadata": {
        "id": "76WEL2SLxicJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "data = [(\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600), \\\n",
        "    (\"Robert\", \"Sales\", 4100), \\\n",
        "    (\"Maria\", \"Finance\", 3000), \\\n",
        "    (\"James\", \"Sales\", 3000), \\\n",
        "    (\"Scott\", \"Finance\", 3300), \\\n",
        "    (\"Jen\", \"Finance\", 3900), \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000), \\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  ]\n",
        "columns= [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "#Distinct\n",
        "distinctDF = df.distinct()\n",
        "print(\"Distinct count: \"+str(distinctDF.count()))\n",
        "distinctDF.show(truncate=False)\n",
        "\n",
        "#Drop duplicates\n",
        "df2 = df.dropDuplicates()\n",
        "print(\"Distinct count: \"+str(df2.count()))\n",
        "df2.show(truncate=False)\n",
        "\n",
        "#Drop duplicates on selected columns\n",
        "dropDisDF = df.dropDuplicates([\"department\",\"salary\"])\n",
        "print(\"Distinct count of department salary : \"+str(dropDisDF.count()))\n",
        "dropDisDF.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A317aTlNnuQB",
        "outputId": "4697d4b7-f346-408b-e919-c7e4cd7d049b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n",
            "Distinct count: 9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|Michael      |Sales     |4600  |\n",
            "|James        |Sales     |3000  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n",
            "Distinct count: 9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|Michael      |Sales     |4600  |\n",
            "|James        |Sales     |3000  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n",
            "Distinct count of department salary : 8\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|Maria        |Finance   |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Michael      |Sales     |4600  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MAP()**"
      ],
      "metadata": {
        "id": "BhL_AFWZ2f12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "data = [\"Project\",\n",
        "\"Gutenberg’s\",\n",
        "\"Alice’s\",\n",
        "\"Adventures\",\n",
        "\"in\",\n",
        "\"Wonderland\",\n",
        "\"Project\",\n",
        "\"Gutenberg’s\",\n",
        "\"Adventures\",\n",
        "\"in\",\n",
        "\"Wonderland\",\n",
        "\"Project\",\n",
        "\"Gutenberg’s\"]\n",
        "\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "\n",
        "rdd2=rdd.map(lambda x: (x,1))\n",
        "for element in rdd2.collect():\n",
        "    print(element)\n",
        "\n",
        "data = [('James','Smith','M',30),\n",
        "  ('Anna','Rose','F',41),\n",
        "  ('Robert','Williams','M',62),\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "df.show()\n",
        "\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x[0]+\",\"+x[1],x[2],x[3]*2)\n",
        "    )\n",
        "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
        "df2.show()\n",
        "\n",
        "#Referring Column Names\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x[\"firstname\"]+\",\"+x[\"lastname\"],x[\"gender\"],x[\"salary\"]*2)\n",
        "    )\n",
        "\n",
        "#Referring Column Names\n",
        "rdd2=df.rdd.map(lambda x:\n",
        "    (x.firstname+\",\"+x.lastname,x.gender,x.salary*2)\n",
        "    )\n",
        "\n",
        "def func1(x):\n",
        "    firstName=x.firstname\n",
        "    lastName=x.lastname\n",
        "    name=firstName+\",\"+lastName\n",
        "    gender=x.gender.lower()\n",
        "    salary=x.salary*2\n",
        "    return (name,gender,salary)\n",
        "\n",
        "rdd2=df.rdd.map(lambda x: func1(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bvIaadnxx73",
        "outputId": "43de2a8f-e164-4698-d694-6b6b1d871ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Alice’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "('Adventures', 1)\n",
            "('in', 1)\n",
            "('Wonderland', 1)\n",
            "('Project', 1)\n",
            "('Gutenberg’s', 1)\n",
            "+---------+--------+------+------+\n",
            "|firstname|lastname|gender|salary|\n",
            "+---------+--------+------+------+\n",
            "|    James|   Smith|     M|    30|\n",
            "|     Anna|    Rose|     F|    41|\n",
            "|   Robert|Williams|     M|    62|\n",
            "+---------+--------+------+------+\n",
            "\n",
            "+---------------+------+----------+\n",
            "|           name|gender|new_salary|\n",
            "+---------------+------+----------+\n",
            "|    James,Smith|     M|        60|\n",
            "|      Anna,Rose|     F|        82|\n",
            "|Robert,Williams|     M|       124|\n",
            "+---------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FLAT MAP()**"
      ],
      "metadata": {
        "id": "HGLlGXma49QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "data = [\"Project Gutenberg’s\",\n",
        "        \"Alice’s Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\",\n",
        "        \"Adventures in Wonderland\",\n",
        "        \"Project Gutenberg’s\"]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "for element in rdd.collect():\n",
        "    print(element)\n",
        "\n",
        "#Flatmap\n",
        "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
        "for element in rdd2.collect():\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJy6XD_B2jRK",
        "outputId": "373f710c-b638-4ba3-ca21-37d8a3b7c8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project Gutenberg’s\n",
            "Alice’s Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Adventures in Wonderland\n",
            "Project Gutenberg’s\n",
            "Project\n",
            "Gutenberg’s\n",
            "Alice’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n",
            "Adventures\n",
            "in\n",
            "Wonderland\n",
            "Project\n",
            "Gutenberg’s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unfortunately, PySpark DataFame doesn’t have flatMap() transformation however, DataFrame has explode() SQL function that is used to flatten the column.**"
      ],
      "metadata": {
        "id": "sJ0bFne-5gLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()\n",
        "\n",
        "arrayData = [\n",
        "        ('James',['Java','Scala'],{'hair':'black','eye':'brown'}),\n",
        "        ('Michael',['Spark','Java',None],{'hair':'brown','eye':None}),\n",
        "        ('Robert',['CSharp',''],{'hair':'red','eye':''}),\n",
        "        ('Washington',None,None),\n",
        "        ('Jefferson',['1','2'],{})]\n",
        "df = spark.createDataFrame(data=arrayData, schema = ['name','knownLanguages','properties'])\n",
        "\n",
        "from pyspark.sql.functions import explode\n",
        "df2 = df.select(df.name,explode(df.knownLanguages))\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqVUiNj35Adr",
        "outputId": "2dc07e9b-27b7-4bee-e164-0160da087d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- col: string (nullable = true)\n",
            "\n",
            "+---------+------+\n",
            "|     name|   col|\n",
            "+---------+------+\n",
            "|    James|  Java|\n",
            "|    James| Scala|\n",
            "|  Michael| Spark|\n",
            "|  Michael|  Java|\n",
            "|  Michael|  NULL|\n",
            "|   Robert|CSharp|\n",
            "|   Robert|      |\n",
            "|Jefferson|     1|\n",
            "|Jefferson|     2|\n",
            "+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df=spark.range(100)\n",
        "print(df.sample(0.05,123).collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27UNq-cl5EiK",
        "outputId": "062d638c-99ce-46b5-9ae1-53d052750b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(id=36), Row(id=75), Row(id=97)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45eDBACt8MD5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}